---
title: "MIC simulation"
output: html_notebook
---

# MIC "package": contains the wrapper MIC and utility functions 
```{r}
library(pROC)
library(dplyr)
library(icenReg)

MIC <- function(df, method, user_formula = NULL, cov = NULL) {
  
  if(method == "np"){
    model <- ic_np(cbind(df$L, df$R))
  } else if(method %in% c("po", "ph")){
    full_formula <- as.formula(
      paste("Surv(L, R, type = 'interval2') ~", user_formula)
    )
    model <- ic_sp(full_formula, data = df, model = method)
  } else if(method %in% c("roc", "pred", "pred.adj")){
    if(method == "roc"){
      library(pROC)
      rocobj <- roc(Indicator ~ Delta, data = df, quiet = TRUE)
      cuty <- coords(rocobj, x = "best", input = "threshold", ret = "threshold", 
                     best.method = "youden", transpose = TRUE)
      threshold <- sample(cuty, 1)
      model <- list(method = "roc", threshold = threshold)
      
    } else if(method == "pred"){
      prev <- mean(df$Indicator)
      logods <- log(prev/(1 - prev))
      fit <- glm(Indicator ~ Delta, data = df, family = "binomial")
      c_ <- coef(fit)[1]
      b_ <- coef(fit)[2]
      threshold <- (logods - c_) / b_
      model <- list(method = "pred", fit = fit, threshold = threshold)
      
    } else if(method == "pred.adj"){
      prev <- mean(df$Indicator)
      logods <- log(prev/(1 - prev))
      fit <- glm(Indicator ~ Delta, data = df, family = "binomial")
      c_ <- coef(fit)[1]
      b_ <- coef(fit)[2]
      mic.pred <- (logods - c_) / b_
      SD <- sd(df$Delta)
      Cor <- cor(df$Delta, df$Indicator)
      Scf <- 0.09 * SD + 0.103 * SD * Cor
      threshold <- mic.pred - Scf * logods
      model <- list(method = "pred.adj", fit = fit, threshold = threshold)
    }
  } else {
    stop("Unsupported method: ", method)
  }
  
  # For the new methods, we use the estimated threshold as meanT.
  if(method %in% c("roc", "pred", "pred.adj")){
    meanT <- model$threshold
  } else {
    if(is.null(cov)){
      n <- nrow(df)
      v <- numeric(n)
      cov_vec <- extract_covs(user_formula)
      for (i in 1:n){
        v[i] <- mean_from_surv(model, df[i, cov_vec])
      }
      meanT <- mean(v)
    } else {
      meanT <- mean_from_surv(model, cov)
    }
  }
  
  meanD <- mean(df$Delta)
  
  result <- list(
    model = model,
    meanT = meanT,
    meanD = meanD
  )
  
  return(result)
}

tv_distance <- function(p, q) {
  0.5 * sum(abs(p - q))
}


# Assume the scores are in {1, 2, ..., score_max}

#For NPMLE 
#max_score set to 5 always



#Assume the scores are in {1, 2, ..., score_max}
transform_df <- function(df, score_max){

  #check if there is non-sensicle data 
  if(any(df$Delta < 1 & df$Indicator == 1)){ 
    warning("Exists at least one patient with no score improvement but reports feeling significantly better")
  }
  if(any(df$Delta == (score_max-1) & df$Indicator == 0)){ 
    warning("Exists at least one patient with max score improvement but does not feel significantly better")
  }
  
  df$L <- ifelse(df$Indicator == 1, 0, df$Delta) # (0, score_max - 1] not (1, score_max - 1]
  df$R <- ifelse(df$Indicator == 1, df$Delta, score_max-1) 
  
  return(df)
}

pmf <- function(model, cov = NULL, max_time) {
  
  model <- getSCurves(model, cov)  

  # Extract Turnbull intervals
  Tbull_ints <- model$Tbull_ints
  
  # Extract survival curve estimates
  S_curve <- model$S_curves[[1]]
  k <- length(S_curve)
  
  # Compute probability masses from the survival drops
  p <- numeric(k)
  p[1] <- 1 - S_curve[1]
  if (k > 1) {
    p[2:k] <- S_curve[1:(k - 1)] - S_curve[2:k]
  }
  
  # Initialize a fixed-length PMF
  pmf_fixed <- numeric(max_time)
  
  # Observed event times (excluding first element)
  observed_times <- Tbull_ints[, 2][-1]
  
  # Assign observed probabilities to correct indices
  for (i in seq_along(observed_times)) {
    time_point <- observed_times[i]
    if (time_point <= max_time && time_point >= 1) {
      pmf_fixed[time_point] <- p[i + 1] # +1 due to removal of first element earlier
    }
  }
  
  result <- list("x" = 1:max_time, "y" = pmf_fixed)
  return(result)
}


mean_from_surv <- function(model, cov = NULL) {
  
  model <- getSCurves(model, cov)  

  # Extract Turnbull intervals (a k x 2 matrix)
  Tbull_ints <- model$Tbull_ints
  
  # Extract survival curve estimates
  S_curve <- model$S_curves[[1]] #rather strange, but this is how it goes
  k <- length(S_curve)
  
  # Compute probability masses from the survival drops:
  p <- numeric(k)
  p[1] <- 1 - S_curve[1]
  if (k > 1) {
    p[2:k] <- S_curve[1:(k - 1)] - S_curve[2:k]
  }
  
  points <- Tbull_ints[, 2]
  mean_event_time <- sum(p * points)
  
  return(mean_event_time)
  
}

#written by ChatGPT
#Utility function that extracts the cov from user_formula
#Used for computing E[T] =E[E[T|X]]
extract_covs <- function(formula_str) {
  # Remove spaces
  formula_str <- gsub(" ", "", formula_str)
  
  # Split the string by '+'
  terms <- unlist(strsplit(formula_str, "\\+"))
  
  # For each term, remove the 'factor()' wrapper if it exists
  terms <- sapply(terms, function(x) {
    if (grepl("^factor\\(", x)) {
      # Extract the content inside factor()
      sub("^factor\\((.*)\\)$", "\\1", x)
    } else {
      x
    }
  })
  return(terms)
}

```


#np_sim functions 
```{r}

simulate_data_np <- function(n, seed = NULL, setup = 0, cov = NULL) { #cov = NULL is for facilitating generic simulation
  
  k <- 10 #so score goes from 1 to 5
  
  # Define possible values for Delta and T
  delta_vals <- -k:k   # Delta takes values from -4 to 4 (9 categories)
  T_vals     <- 1:k    # T takes values from 1 to 5 (5 categories)
  
  # Pre-allocate vectors for Delta and T.
  max_score <- numeric(1)
  Delta <- numeric(n)
  T <- numeric(n)
  trueT <- numeric(1)
  
  #Covariates generation 
  sex <- sample(0:1, n, replace = TRUE, prob = rep(1/2, 2))
  race <- sample(0:2, n, replace = TRUE, prob = rep(1/3, 3))
  age <- rnorm(n, mean = 80, sd = 5)
  
  #Sample Delta and T conditionally on the covariates
# Sample Delta and T conditionally on the covariates using switch
  switch(as.character(setup),
    "0" = { #Uniform T and delta 
      
      for (i in 1:n) {
        weights_delta <- rep(1/(2*k + 1), 2*k + 1)
        Delta[i] <- sample(delta_vals, 1, prob = weights_delta)
        weights_T <- rep(1/k, k)
        T[i] <- sample(T_vals, 1, prob = weights_T)
      }
    },
      "1" = { #(X,D,T) mutually independent; allow for specification of marginal distribution of T and D 
        
        T_probs <- exp(c(2, 1, 0, 0))
        T_probs <- T_probs / sum(T_probs)
        
        eta_ <- c(0, 0.1, 0.2, 0.5, 3, 2, 1, 0.5, 0.1)
        D_probs <- exp(eta_) / sum(exp(eta_))
        
        T <- sample(T_vals, size = n, prob = T_probs, replace = TRUE)
        Delta <- sample(delta_vals, n, prob = D_probs, replace = TRUE)
        
    },
      "2" = { #T and D are not independent; T is inversely related to D; violation of the independence assumption 
        
      d_vec <- c(0, 0.1, 0.2, 0.5, 3, 2, 1, 0.5, 0.1)
      D_probs <- exp(d_vec) / sum(exp(d_vec))
      Delta <- sample(delta_vals, n, prob = D_probs, replace = TRUE)
      
      T <- pmin(4 - Delta + 1, 4) #max_score = 4
    },
      
      "3" = { 
        
      eta_ <- c(0, 0.1, 0.2, 0.5, 3, 2, 1, 0.5, 0.1)
      
      vec1 <- c(2, 1, 0, 0)
      vec2 <- c(0, 1, 2, 0)
      vec3 <- c(0, 3, 1, 0)
      
      mat_race <- cbind(vec1, vec2, vec3)
      
      vec1_ <- c(0.3, 1, -0.3, -0.1)
      vec2_ <- c(0, 0, 1, 0.3)
      
      mat_sex <- cbind(vec1_, vec2_)
      
      for (i in 1:n) {
        T_probs <- exp(mat_race[, race[i] + 1] + mat_sex[, sex[i] + 1])
        T_probs <- T_probs / sum(T_probs)
        
        D_probs <- exp(eta_)
        D_probs <- D_probs / sum(D_probs)
        
        T[i] <- sample(T_vals, size = 1, prob = T_probs)
        Delta[i] <- sample(delta_vals, 1, prob = D_probs)
      }
      
    },
    
    stop("Invalid setup value")
  )
  
  #Compute the indicator variable (feeling significantly better)
  Indicator <- as.integer(Delta >= T) #indicator whether patient feel significantly improved 
  
  #Combine into a data frame
  # 'race' remains as a numeric variable.
  df <- data.frame(
    Delta = Delta,
    T = T,
    Indicator = Indicator,
    race = race,
    sex = sex,
    cont = age
  )
  return(df)
}


np_sim <- function(n,m, setup, cov = NULL){ #cov = NULL is a just a placeholder to faciliate generic simulation; never used in the function
  
  #truth simulation 
  vec <- numeric(m)
  data_large <- simulate_data_np(10000, setup)
  true_mean <- mean(data_large$T)
  
    
  full_support <- c(1:10)
  true_pmf <- prop.table(table(factor(data_large$T, levels = full_support)))
  
  #repeated experiment
  tv_dist_vec = numeric(m)
  
  for(i in 1:m){
    data_oracle <- simulate_data_np(n, setup)
    data_observed <- subset(data_oracle, select = -T) #dataframe without T
    df <- transform_df(data_observed, score_max = 11)
    
    true_mean = mean(data_oracle$T)
    fit_np <- MIC(df, "np")
    vec[i] <- abs(true_mean - fit_np$meanT)
    #print("**********")
    #print(true_pmf)
    #print(pmf(fit_np$model, max_time = 10)$y)
    tv_dist_vec[i] <- tv_distance(true_pmf, pmf(fit_np$model, max_time = 10)$y) #NPMLE simulation only considers max_time = 4 
  }
  
  result <- list(
    abs_dif = vec,
    tv_dist = mean(tv_dist_vec),
    n = n,
    m = m,
    setup = setup
  )
  
  class(result) <- "np_sim"
  return(result)
}

print.np_sim <- function(x, ...) {
  cat("NPMLE Simulation Results\n")
  cat("------------------------\n")
  cat("Parameters: n =", x$n, ", m =", x$m, ", setup =", x$setup, "\n\n")
  cat("MSE:", mean((x$abs_dif)**2, na.rm = TRUE), "\n")
  cat("95th percentile of MSE:", 
      as.numeric(quantile((x$abs_dif)**2, probs = 0.95, na.rm = TRUE)), "\n")
  cat("MAD:", mean(x$abs_dif, na.rm = TRUE), "\n")
  cat("95th percentile of MADs:", 
      as.numeric(quantile(x$abs_dif, probs = 0.95, na.rm = TRUE)), "\n")
  cat("Average TV distance:", mean(x$tv_dist, na.rm = TRUE), "\n")
  
  invisible(x)
}


```


#np sanity check
```{r}
df <- simulate_data_np(n=500)
df <- transform_df(df, score_max = 11)
head(df)
result_ <- MIC(df, "pred")
result_
```




The hazard function is specified by $h(t|x) = \lambda \gamma t^{\gamma-1} \exp(x'\beta)$ 


#ph_sim functions 
```{r}
library(fastDummies)
library(simsurv)

simulate_data_ph <- function(n, seed = NULL, setup = 0, cov = NULL) {
  if (!is.null(seed)) set.seed(seed)

  race <- factor(sample(0:2, size = n, replace = TRUE), levels = c(0, 1, 2))
  sex <- factor(sample(0:1, size = n, replace = TRUE), levels = c(0, 1))
  cont <- rnorm(n, mean = 80, sd = sqrt(5))

  eta <- c(-10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 3, 2.5, 2.5, 2.5, 2, 1, 1, 0.5, 0.5, 0.5, 0.3)
  D_probs <- exp(eta) / sum(exp(eta))
  Delta <- sample(-10:10, size = n, replace = TRUE, prob = D_probs)

  cov_data <- data.frame(
    id = 1:n,
    race = race,
    sex = sex,
    cont = cont,
    Delta = Delta
  )

  cov_data_dummy <- fastDummies::dummy_cols(
    cov_data,
    select_columns = c("race", "sex"),
    remove_first_dummy = TRUE,
    remove_selected_columns = TRUE
  )

  cov_data_sim <- cov_data_dummy[, c("id", "race_1", "race_2", "sex_1", "cont")]

  # Specify the baseline discrete hazard (hand-specified for times 1 to 10)
  baseline_hazard <- c(0.01, 0.03, 0.1, 0.2, 0.3, 0.35, 0.4, 0.5, 0.6, 0.04) #latter values needs to be larger...
  
  switch(as.character(setup),
    "0" = { 
      betas <- c(race_1 = 0.5, race_2 = -0.3, sex_1 = 0.2, cont = 0.01)
    },
    stop("Invalid setup value")
  )

  if(!is.null(cov)){
    for (name in names(cov)) {
      if (name %in% names(cov_data_sim)) {
        cov_data_sim[[name]] <- rep(cov[[name]], n)
      } else {
        stop(paste("Covariate", name, "not found in the data."))
      }
    }
  }

  linpred <- as.matrix(cov_data_sim[, names(betas)]) %*% betas

  sample_discrete_ph <- function(lp, baseline_hazard) {
    for (t in seq_along(baseline_hazard)) {
      hazard_t <- baseline_hazard[t] * exp(lp)
      hazard_t <- pmin(hazard_t, 1)
      event <- rbinom(1, 1, hazard_t)
      if (event == 1) return(t)
    }
    return(length(baseline_hazard) + 1)
  }

  event_times <- sapply(linpred, sample_discrete_ph, baseline_hazard)

  final_data <- merge(cov_data, cov_data_sim[, !(names(cov_data_sim) %in% c("cont"))], by = "id")
  final_data$T <- pmin(event_times, 10)
  final_data$Indicator <- as.integer(final_data$Delta >= final_data$T)

  return(final_data)
}


ph_sim <- function(n,m, setup, cov = NULL){ 
  
  #this can be either 
  data_large <- simulate_data_ph(n = 10000, setup = setup, cov =cov)
  true_mean <- mean(data_large$T)
  
  full_support <- c(1:10)
  true_pmf <- prop.table(table(factor(data_large$T, levels = full_support)))


  vec <- numeric(m)
  tv_dist_vec = numeric(m)

  #models on restricted data;
  for(i in 1:m){
    data_oracle <- simulate_data_ph(n = n, setup = setup)
    data_observed <- subset(data_oracle, select = -T) #dataframe without T
    df_ <- transform_df(data_observed, score_max = 11)
    
    fit_ph <- MIC(df_, user_formula = "cont + factor(sex) + factor(race)","ph", cov)
    print("*********")
    print(true_pmf)
    print(pmf(fit_ph$model, max_time = 10)$y)
    
    vec[i] <- abs(true_mean - fit_ph$meanT)
    tv_dist_vec[i] <- tv_distance(true_pmf, pmf(fit_ph$model, cov, max_time = 10)$y)
  }

  result <- list(
    abs_dif = vec,
    tv_dist = tv_dist_vec, #abs_dif and tv_dist are vectors 
    n = n,
    m = m,
    setup = setup
  )
  
  class(result) <- "ph_sim"
  return(result) #will need to skips the nulls (caused by Max iteration reached)
}

print.ph_sim <- function(x) {
  cat("ph Simulation Results\n")
  cat("------------------------\n")
  cat("Parameters: n =", x$n, ", m =", x$m, ", setup =", x$setup, "\n\n")
  cat("MSE:", mean((x$abs_dif)**2, na.rm = TRUE), "\n")
  cat("95th percentile of MSE:", 
      as.numeric(quantile((x$abs_dif)**2, probs = 0.95, na.rm = TRUE)), "\n")
  cat("MAD:", mean(x$abs_dif, na.rm = TRUE), "\n")
  cat("95th percentile of MADs:", 
      as.numeric(quantile(x$abs_dif, probs = 0.95, na.rm = TRUE)), "\n")
  cat("Average TV distance:", mean(x$tv_dist, na.rm = TRUE), "\n")
  
  invisible(x)
}

```


```{r}
library(ggplot2)

df_ph_oracle <- simulate_data_ph(10000, setup = 0)

barplot(table(df_ph_oracle$T),
        main = "Bar Plot of Discrete Event Times",
        xlab = "Event Time (T)",
        ylab = "Frequency",
        col = "lightblue")

barplot(table(df_ph_oracle$Delta),
        main = "Bar Plot of Discrete Event Times",
        xlab = "Change (Delta)",
        ylab = "Frequency",
        col = "lightblue")

ggplot(df_ph_oracle, aes(x = T, y = Delta)) +
  geom_bin2d(bins = 30) +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "2-D Histogram of T and Delta", x = "T", y = "Delta")


#sink("simulation_output_ph.txt")

result <- print(ph_sim(n=100, m=10, setup = 0))
#print(ph_sim(n=500, m=200, setup = 0))
#print(ph_sim(n=1000, m=200, setup = 0))

#unsink()

```


#po_sim functions
```{r}
library(fastDummies)

#po simulation 
simulate_data_po <- function(n, seed = NULL, setup = 0, cov = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  # 'race' with numeric codes 0, 1, 2 (treated as categorical)
  race <- factor(sample(0:2, size = n, replace = TRUE), levels = c(0, 1, 2))
  # 'sex' with numeric codes 0 and 1 (treated as categorical)
  sex <- factor(sample(0:1, size = n, replace = TRUE), levels = c(0, 1))
  
  # Generate continuous covariate: Gaussian(80, variance = 5)
  cont <- rnorm(n, mean = 80, sd = sqrt(5))
  
  eta <- c(-10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 3, 2.5, 2.5, 2.5, 2, 1, 1, 0.5, 0.5, 0.5, 0.3)
  D_probs <- exp(eta) / sum(exp(eta))
  Delta <- sample(-10:10, size = n, replace = TRUE, prob = D_probs)
  
  # Create a data frame with the raw covariates and an identifier
  cov_data <- data.frame(
    id = 1:n,
    race = race,
    sex = sex,
    cont = cont,
    Delta = Delta
  )
  
  # One-hot encode the categorical variables using fastDummies.
  cov_data_dummy <- dummy_cols(
    cov_data,
    select_columns = c("race", "sex"),
    remove_first_dummy = TRUE,
    remove_selected_columns = TRUE
  )
  
  # Combine the one-hot encoded variables with the id and continuous variable.
  cov_data_sim <- cov_data_dummy[, c("id", "race_1", "race_2", "sex_1", "cont")]
  
  # Specify the baseline discrete odds (hand-specified for times 1 to 10)
  baseline_odds <- c(0.01, 0.03, 0.1, 0.2, 0.3, 0.35, 0.4, 0.5, 0.6, 0.04)
  
  switch(as.character(setup),
    "0" = { 
      betas <- c(race_1 = 0.5, race_2 = -0.3, sex_1 = 0.2, cont = 0.01)
    },
    stop("Invalid setup value")
  )
  
  # If covariates are fixed, override the generated values
  if(!is.null(cov)){
    for (name in names(cov)) {
      if (name %in% names(cov_data_sim)) {
        cov_data_sim[[name]] <- rep(cov[[name]], n)
      } else {
        stop(paste("Covariate", name, "not found in the data."))
      }
    }
  }
  
  linpred <- as.matrix(cov_data_sim[, names(betas)]) %*% betas
  
  sample_discrete_po <- function(lp, baseline_odds) {
    for (t in seq_along(baseline_odds)) {
      odds_t <- baseline_odds[t] * exp(lp)
      p_event <- odds_t / (1 + odds_t)
      p_event <- pmin(p_event, 1)
      event <- rbinom(1, 1, p_event)
      if (event == 1) return(t)
    }
    return(length(baseline_odds) + 1)
  }
  
  event_times <- sapply(linpred, sample_discrete_po, baseline_odds)
  
  # Merge simulation output with the original covariate data
  final_data <- merge(cov_data, cov_data_sim[, !(names(cov_data_sim) %in% c("cont"))], by = "id")
  final_data$T <- pmin(event_times, 10)
  final_data$Indicator <- as.integer(final_data$Delta >= final_data$T)
  
  return(final_data)
}

po_sim <- function(n, m, setup, cov = NULL){ 
  # Use a large sample to get the true distribution of T
  data_large <- simulate_data_po(n = 10000, setup = setup, cov = cov)
  true_mean <- mean(data_large$T)
    
  full_support <- c(1:10)
  true_pmf <- prop.table(table(factor(data_large$T, levels = full_support)))
  
  vec <- numeric(m)
  tv_dist_vec <- numeric(m)
  
  # Models on restricted data
  for(i in 1:m){
    data_oracle <- simulate_data_po(n = n, setup = setup)
    data_observed <- subset(data_oracle, select = -T) # dataframe without T
    df_ <- transform_df(data_observed, score_max = 11)
    
    fit_po <- MIC(df_, user_formula = "cont + factor(sex) + factor(race)", "po", cov)
    
    vec[i] <- abs(true_mean - fit_po$meanT)
    tv_dist_vec[i] <- tv_distance(true_pmf, pmf(fit_po$model, cov, max_time = 10)$y)
  }
  
  result <- list(
    abs_dif = vec,
    tv_dist = tv_dist_vec, # abs_dif and tv_dist are vectors 
    n = n,
    m = m,
    setup = setup
  )
  
  class(result) <- "po_sim"
  return(result) # will need to skips the nulls (caused by Max iteration reached)
}

print.po_sim <- function(x) {
  cat("po Simulation Results\n")
  cat("------------------------\n")
  cat("Parameters: n =", x$n, ", m =", x$m, ", setup =", x$setup, "\n\n")
  cat("MSE:", mean((x$abs_dif)**2, na.rm = TRUE), "\n")
  cat("95th percentile of MSE:", 
      as.numeric(quantile((x$abs_dif)**2, probs = 0.95, na.rm = TRUE)), "\n")
  cat("MAD:", mean(x$abs_dif, na.rm = TRUE), "\n")
  cat("95th percentile of MADs:", 
      as.numeric(quantile(x$abs_dif, probs = 0.95, na.rm = TRUE)), "\n")
  cat("Average TV distance:", mean(x$tv_dist, na.rm = TRUE), "\n")
  
  invisible(x)
}

```

```{r}

df_po_oracle <- simulate_data_po(10000, setup = 0)

barplot(table(df_po_oracle$T),
        main = "Bar Plot of Discrete Event Times",
        xlab = "Event Time (T)",
        ylab = "Frequency",
        col = "lightblue")

barplot(table(df_po_oracle$Delta),
        main = "Bar Plot of Discrete Event Times",
        xlab = "Change (Delta)",
        ylab = "Frequency",
        col = "lightblue")

ggplot(df_po_oracle, aes(x = T, y = Delta)) +
  geom_bin2d(bins = 30) +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "2-D Histogram of T and Delta", x = "T", y = "Delta")

result <- print(po_sim(n=10000, m=10, setup = 0))
```



#Generic function for simulation

```{r}

#separation of the sim_model and fit model
generic_sim <- function(n, m, setup, cov = NULL, sim_model = "simulate_data_np", model = "np") { 
  # Retrieve the simulation function based on the provided name
  sim <- get(sim_model)
  
  # Use a large sample to get the true distribution of T
  data_large <- sim(n = 10000, setup = setup, cov = cov)
  true_mean <- mean(data_large$T)
  
  full_support <- 1:10
  true_pmf <- prop.table(table(factor(data_large$T, levels = full_support)))
  
  vec <- numeric(m)
  tv_dist_vec <- numeric(m)
  
  # Models on restricted data
  for(i in 1:m) {
    # Note: cov parameter is not passed here to mimic the original function.
    data_oracle <- sim(n = n, setup = setup)
    data_observed <- subset(data_oracle, select = -T)  # dataframe without T
    df_ <- transform_df(data_observed, score_max = 11)
    
    # For new methods, do not pass user_formula
    if(model %in% c("roc", "pred", "pred.adj")){
      fit <- MIC(df_, method = model, cov = cov)
    } else {
      fit <- MIC(df_, user_formula = "cont + factor(sex) + factor(race)", method = model, cov = cov)
    }
    
    vec[i] <- abs(fit$meanT - true_mean)
    
    # For new methods, density estimates are not provided so TV distance is NA.
    if(model %in% c("roc", "pred", "pred.adj")){
      tv_dist_vec[i] <- NA
    } else {
      tv_dist_vec[i] <- tv_distance(true_pmf, pmf(fit$model, cov, max_time = 10)$y)
    }
  }
  
  result <- list(
    model = model, 
    dif = vec,
    tv_dist = tv_dist_vec,  # For new methods this will be NA
    n = n,
    m = m,
    setup = setup
  )
  
  class(result) <- "mega"
  return(result)
}

#setup is fixed 
run_simulations <- function(setup, cov = NULL, m = 200) {
  # Define the sample sizes and simulation model choices
  n_values <- c(100, 500, 1000)
  sim_models <- c("simulate_data_po", "simulate_data_ph", "simulate_data_np", "simulate_data_real")
  models <- c("np", "ph", "po", "roc", "pred", "pred.adj")
  
  # Container to store results for each combination
  results_list <- list()
  
  # Loop over each sample size and simulation/model choice
  for (n_val in n_values) {
    for (i in seq_along(sim_models)) {
      for (j in seq_along(models)) {
        sim_model <- sim_models[i]
        model <- models[j]

        # Call the generic simulation function
        sim_result <- generic_sim(n = n_val, m = m, setup = setup, cov = cov,
                                  sim_model = sim_model, model = model)
        
        # Create a key for the result list, e.g. "n_100_po"
        key <- paste("n", n_val, sim_model, "fit_model", model, sep = "_")
        results_list[[key]] <- sim_result 
      }
    }
  }
  
  return(results_list)
}

print.mega <- function(x) {
  cat(x$model, "Simulation Results\n")
  cat("------------------------\n")
  cat("Parameters: n =", x$n, ", m =", x$m, ", setup =", x$setup, "\n\n")
  
  cat("MSE:", mean((x$dif)^2, na.rm = TRUE), "\n")
  cat("95th percentile of MSE:", 
      as.numeric(quantile((x$dif)^2, probs = 0.95, na.rm = TRUE)), "\n")
  cat("MAD:", mean(abs(x$dif), na.rm = TRUE), "\n")
  cat("95th percentile of MADs:", 
      as.numeric(quantile(abs(x$dif), probs = 0.95, na.rm = TRUE)), "\n")
  
  if(all(is.na(x$tv_dist))) {
    cat("Average TV distance: Not available\n")
  } else {
    cat("Average TV distance:", mean(x$tv_dist, na.rm = TRUE), "\n")
  }
  
  invisible(x)
}

```


```{r}
time_taken <- system.time({
  mega_result <- run_simulations(setup = 0, m = 1)
})

#save(mega_result, file = "mega_result.RData")

# Accessing the elapsed time by name
elapsed_time <- time_taken["elapsed"]
print(elapsed_time)

print(mega_result)
```
#A final simulation model; T and Delta aren't conditionally independent given the covariates 
```{r}
simulate_data_real <- function(n, seed = NULL, setup = 0, cov = NULL) { #setup is dummmy for now
  if (!is.null(seed)) set.seed(seed)
  
  # Define possible values:
  Delta_vals <- -10:10      # Δ corresponds to change in pain level
  T_vals     <- 1:10        # T corresponds to the patient's minimal important change
  
  # Pre-allocate vectors for Δ and T
  Delta <- numeric(n)
  T     <- numeric(n)
  
  # Covariate generation:
  sex  <- sample(0:1, n, replace = TRUE)         # 0/1 indicator for sex
  race <- sample(0:2, n, replace = TRUE)           # e.g., 0, 1, 2 for different race groups
  age  <- rnorm(n, mean = 65, sd = 10)             # age with mean 65 and sd 10
  
  # Simulate Δ (pain change) and T (minimal important change)
  for (i in 1:n) {
    # Create a baseline probability for Δ values: higher weight near 0 (smaller changes)
    base_probs <- exp(-abs(Delta_vals)/3)
    
    # Optionally, adjust Δ probabilities based on age: older patients might tend to show less improvement
    age_adj <- if (age[i] > 65) exp(-abs(Delta_vals + 2)/3) else rep(1, length(Delta_vals))
    Delta_probs <- base_probs * age_adj
    Delta_probs <- Delta_probs / sum(Delta_probs)
    
    # Sample Δ for the i-th patient:
    Delta[i] <- sample(Delta_vals, 1, prob = Delta_probs)
    
    # Now simulate T conditional on Δ and the covariates.
    # We set a mean for T that is influenced by Δ, sex and race.
    # For instance, a larger Δ (i.e. greater pain improvement) might be associated with a lower minimal change threshold.
    mean_T <- 6 - 0.2 * Delta[i] + 0.5 * sex[i] - 0.3 * (race[i] - 1)
    
    # Create probabilities for T using a normal kernel centered at mean_T.
    T_density <- dnorm(T_vals, mean = mean_T, sd = 1)
    T_probs <- T_density / sum(T_density)
    
    # Sample T for the i-th patient:
    T[i] <- sample(T_vals, 1, prob = T_probs)
  }
  
  # Compute the indicator: whether the patient perceives significant improvement
  # (i.e. the change in pain Δ meets or exceeds the minimal important change T)
  Indicator <- as.integer(Delta >= T)
  
  # Combine all variables into a data frame and return
  df <- data.frame(
    Delta     = Delta,
    T         = T,
    Indicator = Indicator,
    sex       = sex,
    race      = race,
    cont       = age
  )
  
  return(df)
}

run_simulations_real <- function(setup = 0, cov = NULL, m = 200) {
  # Define the sample sizes and simulation model choices
  n_values <- c(100, 500, 1000)
  sim_models <- c("simulate_data_real")
  models <- c("po", "ph", "np")
  
  # Container to store results for each combination
  results_list <- list()
  
  # Loop over each sample size and simulation/model choice
  for (n_val in n_values) {
    for (j in seq_along(models)) {
      sim_model <- sim_models[i]
      model <- ""

      # Call the generic simulation function
      sim_result <- generic_sim(n = n_val, m = m, setup = setup, cov = cov,
                                sim_model = sim_model, model = model)
      
      # Create a key for the result list, e.g. "n_100_po"
      key <- paste("n", n_val, sim_model, "fit_model", model, sep = "_")
      results_list[[key]] <- sim_result 
    }
  }
  
  return(results_list)
}



```


```{r}
mega_result_2 <- run_simulations(setup = 0, m = 200)
mega_result_2

save(mega_result, file = "mega_result_2.RData")



```
